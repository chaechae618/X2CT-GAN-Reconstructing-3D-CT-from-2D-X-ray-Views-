{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec63820",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "\n",
    "class Base_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Base_Model, self).__init__()\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return 'BaseModel'\n",
    "\n",
    "    def init_network(self, opt):\n",
    "        self.opt = opt\n",
    "        self.gpu_ids = opt.gpu_ids\n",
    "        self.device = torch.device('cuda:{}'.format(self.gpu_ids[0])) if (self.gpu_ids and torch.cuda.is_available()) else torch.device('cpu')\n",
    "        self.save_root = os.path.join(opt.MODEL_SAVE_PATH, self.name, opt.data, opt.tag)\n",
    "        self.save_dir = os.path.join(self.save_root, 'checkpoint')\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "        self.loss_names = []\n",
    "        self.metrics_names = []\n",
    "        self.model_names = []\n",
    "        self.visual_names = []\n",
    "        self.image_paths = []\n",
    "        self.optimizers = []\n",
    "\n",
    "    def init_loss(self, opt):\n",
    "        try:\n",
    "            self.criterionGAN = GANLoss(use_lsgan=True).to(self.device)\n",
    "            self.criterionL1 = RestructionLoss(distance='l1').to(self.device)\n",
    "        except ImportError as e:\n",
    "            raise ImportError(f\"Error initializing loss functions: {e}. Ensure required loss classes are defined.\")\n",
    "\n",
    "    def save_networks(self, which_epoch, total_steps=0, latest=False):\n",
    "        for name in self.model_names:\n",
    "            if isinstance(name, str):\n",
    "                save_filename = '{}_net_{}.pth'.format('latest' if latest else which_epoch, name)\n",
    "                save_path = os.path.join(self.save_dir, str(which_epoch) if not latest else '', save_filename)\n",
    "                os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "                net = getattr(self, 'net' + name)\n",
    "                param_dict = net.cpu().state_dict()\n",
    "                torch.save({'iters': total_steps, 'epoch': which_epoch, 'state_dict': param_dict, 'lr': self.optimizers[0].param_groups[0]['lr']}, save_path)\n",
    "\n",
    "    def load_networks(self, which_epoch, load_path=None, latest=False):\n",
    "        for name in self.model_names:\n",
    "            if isinstance(name, str):\n",
    "                load_filename = '{}_net_{}.pth'.format('latest' if latest else which_epoch, name)\n",
    "                full_path = os.path.join(load_path if load_path else self.save_dir, load_filename)\n",
    "                print(f\"Loading model from {full_path}\")\n",
    "                save_dict = torch.load(full_path, map_location=self.device)\n",
    "                state_dict = save_dict['state_dict']\n",
    "                getattr(self, 'net' + name).load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53c1846",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import functools\n",
    "\n",
    "class NLayer_3D_Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm3d, use_sigmoid=False, n_out_channels=1):\n",
    "        super(NLayer_3D_Discriminator, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm3d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm3d\n",
    "\n",
    "        kw = 4\n",
    "        padw = int(np.ceil((kw - 1.0) / 2))\n",
    "        sequence = [[\n",
    "            nn.Conv3d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]]\n",
    "\n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        for n in range(1, n_layers):\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            sequence += [[\n",
    "                nn.Conv3d(ndf * nf_mult_prev, ndf * nf_mult,\n",
    "                          kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
    "                norm_layer(ndf * nf_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]]\n",
    "\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8)\n",
    "        sequence += [[\n",
    "            nn.Conv3d(ndf * nf_mult_prev, ndf * nf_mult,\n",
    "                      kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
    "            norm_layer(ndf * nf_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]]\n",
    "\n",
    "        if use_sigmoid:\n",
    "            sequence += [[nn.Conv3d(ndf * nf_mult, n_out_channels, kernel_size=kw, stride=1, padding=padw),\n",
    "                          nn.Sigmoid()]]\n",
    "        else:\n",
    "            sequence += [[nn.Conv3d(ndf * nf_mult, n_out_channels, kernel_size=kw, stride=1, padding=padw)]]\n",
    "\n",
    "        sequence_stream = []\n",
    "        for n in range(len(sequence)):\n",
    "            sequence_stream += sequence[n]\n",
    "        self.model = nn.Sequential(*sequence_stream)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class UNetLike_DownStep5(nn.Module):\n",
    "    def __init__(self, input_shape, encoder_input_channels, decoder_output_channels, decoder_out_activation):\n",
    "        super(UNetLike_DownStep5, self).__init__()\n",
    "\n",
    "        # Encoder 부분: 기본적인 Conv2d 계층 사용\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(encoder_input_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # Decoder 부분\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(128, decoder_output_channels, kernel_size=3, padding=1),\n",
    "            decoder_out_activation()  # 예: ReLU 또는 LeakyReLU\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "class MultiView_UNetLike_DenseDimensionNet(nn.Module):\n",
    "    def __init__(self, view1Model, view2Model, view1Order, view2Order, backToSub,\n",
    "                 decoder_output_channels, decoder_out_activation, decoder_norm_layer=nn.BatchNorm3d):\n",
    "        super(MultiView_UNetLike_DenseDimensionNet, self).__init__()\n",
    "        self.view1Model = view1Model\n",
    "        self.view2Model = view2Model\n",
    "        self.view1Order = view1Order\n",
    "        self.view2Order = view2Order\n",
    "        self.backToSub = backToSub\n",
    "\n",
    "        self.transposed_layer = Transposed_And_Add(view1Order, view2Order)\n",
    "        self.decoder_layer = nn.Sequential(\n",
    "            nn.Conv3d(decoder_output_channels, decoder_output_channels, kernel_size=7, padding=3, bias=False),\n",
    "            decoder_out_activation()\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        inputs: List of [view1_input, view2_input]\n",
    "        Each input has shape [batch_size, channels, height, width]\n",
    "        \"\"\"\n",
    "        view1_input, view2_input = inputs[0], inputs[1]\n",
    "\n",
    "        # Debugging: Print the shapes of the inputs to see the actual dimensions\n",
    "        print(f\"view1_input shape: {view1_input.shape}\")\n",
    "        print(f\"view2_input shape: {view2_input.shape}\")\n",
    "\n",
    "        batch_size, channels, height, width = view1_input.shape\n",
    "\n",
    "        # Process through 2D models (no unsqueeze here)\n",
    "        view1_output = self.view1Model(view1_input)  # Process 4D input directly\n",
    "        view2_output = self.view2Model(view2_input)  # Process 4D input directly\n",
    "\n",
    "        # Reshape the output back to the correct dimensions (5D if necessary)\n",
    "        out_channels = view1_output.size(1)\n",
    "        view1_output = view1_output.unsqueeze(2)  # Add depth dimension\n",
    "        view2_output = view2_output.unsqueeze(2)  # Add depth dimension\n",
    "\n",
    "        # Multi-view fusion\n",
    "        fused_output = self.transposed_layer(view1_output, view2_output)\n",
    "\n",
    "        # Return all outputs: view1_output, view2_output, and the final fused_output\n",
    "        return self.decoder_layer(fused_output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Transposed_And_Add(nn.Module):\n",
    "    def __init__(self, view1Order, view2Order):\n",
    "        super(Transposed_And_Add, self).__init__()\n",
    "        self.view1Order = view1Order\n",
    "        self.view2Order = view2Order\n",
    "\n",
    "    def forward(self, view1, view2):\n",
    "        \"\"\"\n",
    "        view1: Tensor from view1 model\n",
    "        view2: Tensor from view2 model\n",
    "        \"\"\"\n",
    "        # Debugging: Print original shapes\n",
    "        print(f\"View1 shape before transpose: {view1.shape}\")\n",
    "        print(f\"View2 shape before transpose: {view2.shape}\")\n",
    "\n",
    "        # Adjust view2 dimensions to match view1\n",
    "        if view1.size(2) != view2.size(2):  # Depth mismatch\n",
    "            print(f\"Adjusting depth: {view2.size(2)} -> {view1.size(2)}\")\n",
    "            view2 = nn.functional.interpolate(\n",
    "                view2,\n",
    "                size=(view1.size(2), view1.size(3), view1.size(4)),\n",
    "                mode='trilinear',\n",
    "                align_corners=False\n",
    "            )\n",
    "        elif view1.size(3) != view2.size(3) or view1.size(4) != view2.size(4):  # Height/Width mismatch\n",
    "            print(f\"Adjusting spatial dimensions: {(view2.size(3), view2.size(4))} -> {(view1.size(3), view1.size(4))}\")\n",
    "            view2 = nn.functional.interpolate(\n",
    "                view2,\n",
    "                size=(view1.size(2), view1.size(3), view1.size(4)),\n",
    "                mode='trilinear',\n",
    "                align_corners=False\n",
    "            )\n",
    "\n",
    "        # Transpose tensors\n",
    "        view1_transposed = view1.permute(*self.view1Order)\n",
    "        view2_transposed = view2.permute(*self.view2Order)\n",
    "\n",
    "        # Debugging: Print transposed shapes\n",
    "        print(f\"View1 shape after transpose: {view1_transposed.shape}\")\n",
    "        print(f\"View2 shape after transpose: {view2_transposed.shape}\")\n",
    "\n",
    "        # Compute average\n",
    "        fused_output = (view1_transposed + view2_transposed) / 2\n",
    "        return fused_output\n",
    "\n",
    "\n",
    "# view1Model과 view2Model 정의\n",
    "# 각 뷰에 대해 모델 정의\n",
    "view1Model = UNetLike_DownStep5(input_shape=(320, 320), encoder_input_channels=1, decoder_output_channels=64, decoder_out_activation=nn.ReLU)\n",
    "view2Model = UNetLike_DownStep5(input_shape=(320, 320), encoder_input_channels=1, decoder_output_channels=64, decoder_out_activation=nn.ReLU)\n",
    "\n",
    "# MultiView_UNetLike_DenseDimensionNet 모델 정의\n",
    "multi_view_model = MultiView_UNetLike_DenseDimensionNet(\n",
    "    view1Model=view1Model,\n",
    "    view2Model=view2Model,\n",
    "    view1Order=(0, 1, 2, 3, 4),\n",
    "    view2Order=(0, 1, 2, 3, 4),  # 수정된 부분: 동일한 차원 순서를 사용\n",
    "    backToSub=True,\n",
    "    decoder_output_channels=64,\n",
    "    decoder_out_activation=nn.ReLU\n",
    ")\n",
    "\n",
    "# 임의의 입력 데이터 생성 (배치 크기 1, 채널 1, 높이 320, 너비 320)\n",
    "input_data = [\n",
    "    torch.randn(1, 1, 320, 320),  # view1_input\n",
    "    torch.randn(1, 1, 320, 320)   # view2_input\n",
    "]\n",
    "\n",
    "# 모델 실행\n",
    "fused_output = multi_view_model(input_data)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"fused_output shape: {fused_output.shape}\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Generator 정의\n",
    "class Generator3D(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, encoder_input_shape, encoder_input_channels, decoder_output_channels, decoder_out_activation):\n",
    "        super(Generator3D, self).__init__()\n",
    "\n",
    "        # MultiView_UNetLike_DenseDimensionNet를 사용하여 Generator 구성\n",
    "        self.encoder_model = UNetLike_DownStep5(\n",
    "            input_shape=encoder_input_shape,\n",
    "            encoder_input_channels=encoder_input_channels,\n",
    "            decoder_output_channels=decoder_output_channels,\n",
    "            decoder_out_activation=decoder_out_activation\n",
    "        )\n",
    "\n",
    "        self.decoder_model = UNetLike_DownStep5(\n",
    "            input_shape=encoder_input_shape,\n",
    "            encoder_input_channels=encoder_input_channels,\n",
    "            decoder_output_channels=decoder_output_channels,\n",
    "            decoder_out_activation=decoder_out_activation\n",
    "        )\n",
    "\n",
    "        # 수정된 view1Order 및 view2Order 정의\n",
    "        # 5D 텐서에서 [batch, channel, depth, height, width] 순서임을 고려\n",
    "        self.generator_model = MultiView_UNetLike_DenseDimensionNet(\n",
    "            view1Model=self.encoder_model,\n",
    "            view2Model=self.decoder_model,\n",
    "            view1Order=(0, 1, 2, 3, 4),  # 텐서 순서 그대로 유지\n",
    "            view2Order=(0, 1, 2, 3, 4),  # 텐서 순서 변경 없이 일치하도록 수정\n",
    "            backToSub=True,\n",
    "            decoder_output_channels=output_nc,\n",
    "            decoder_out_activation=decoder_out_activation\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 입력 검증 추가: x는 [view1, view2] 형태로 전달되며, 두 텐서의 크기 일치 필요\n",
    "        if not isinstance(x, list) or len(x) != 2:\n",
    "            raise ValueError(\"Input must be a list containing two tensors: [view1, view2].\")\n",
    "        if x[0].shape != x[1].shape:\n",
    "            raise ValueError(\"The shapes of view1 and view2 must match.\")\n",
    "        return self.generator_model(x)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Discriminator 정의\n",
    "class Discriminator3D(nn.Module):\n",
    "    def __init__(self, input_nc, ndf, n_layers, norm_layer=nn.BatchNorm3d, use_sigmoid=False):\n",
    "        super(Discriminator3D, self).__init__()\n",
    "\n",
    "        # NLayer_3D_Discriminator를 기반으로 Discriminator 구성\n",
    "        self.discriminator_model = NLayer_3D_Discriminator(\n",
    "            input_nc=input_nc,\n",
    "            ndf=ndf,\n",
    "            n_layers=n_layers,\n",
    "            norm_layer=norm_layer,\n",
    "            use_sigmoid=use_sigmoid\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.discriminator_model(x)\n",
    "from easydict import EasyDict\n",
    "\n",
    "# 설정 정의\n",
    "opt = EasyDict({\n",
    "    'lr': 0.0002,\n",
    "    'beta1': 0.5,\n",
    "    'beta2': 0.999,\n",
    "    'pool_size': 50,\n",
    "    'idt_lambda': 0.5,\n",
    "    'gan_lambda': 1.0,\n",
    "    'input_nc_G': 2,\n",
    "    'output_nc_G': 1,\n",
    "    'encoder_input_shape': (320, 320),\n",
    "    'encoder_input_nc': 1,\n",
    "    'ndf': 16,\n",
    "    'n_layers_D': 3,\n",
    "    'input_nc_D': 3,  # 병합된 3채널 입력\n",
    "    'CT_MEAN_STD': [0.0, 1.0],\n",
    "    'XRAY1_MEAN_STD': [0.0, 1.0],\n",
    "    'XRAY2_MEAN_STD': [0.0, 1.0],\n",
    "})\n",
    "class CTGAN(nn.Module):\n",
    "    def __init__(self, opt, generator, discriminator):\n",
    "        super(CTGAN, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Generator와 Discriminator 초기화\n",
    "        self.netG = generator.to(self.device)\n",
    "        self.netD = discriminator.to(self.device)\n",
    "\n",
    "        # 손실 함수 정의\n",
    "        self.criterionGAN = GANLoss(use_lsgan=True).to(self.device)\n",
    "        self.criterionL1 = RestructionLoss(distance='l1').to(self.device)\n",
    "\n",
    "        # Optimizer 정의\n",
    "        self.optimizer_G = Adam(self.netG.parameters(), lr=opt.lr, betas=(opt.beta1, opt.beta2))\n",
    "        self.optimizer_D = Adam(self.netD.parameters(), lr=opt.lr, betas=(opt.beta1, opt.beta2))\n",
    "\n",
    "        # Fake Image Pool\n",
    "        self.fake_pool = ImagePool(opt.pool_size)\n",
    "\n",
    "         # 디버깅 정보를 저장할 속성\n",
    "        self.debug_info = {}\n",
    "\n",
    "    def set_input(self, input_data):\n",
    "        self.xray1 = input_data['front_xray_tensor'].to(self.device)\n",
    "        self.xray2 = input_data['side_xray_tensor'].to(self.device)\n",
    "        self.ct_volume = input_data['ct_volume_tensor'].to(self.device)\n",
    "\n",
    "    def forward(self):\n",
    "        self.fake_ct = self.netG([self.xray1, self.xray2])\n",
    "\n",
    "    def backward_D(self):\n",
    "        # X-ray 텐서를 5D로 확장\n",
    "        xray1_5d = self.xray1.unsqueeze(2)  # [1, 1, 1, 320, 320]\n",
    "        xray2_5d = self.xray2.unsqueeze(2)  # [1, 1, 1, 320, 320]\n",
    "\n",
    "        # X-ray 크기 조정\n",
    "        xray1_resized = torch.nn.functional.interpolate(\n",
    "            xray1_5d, size=self.ct_volume.shape[2:], mode='trilinear', align_corners=False\n",
    "        )\n",
    "        xray2_resized = torch.nn.functional.interpolate(\n",
    "            xray2_5d, size=self.ct_volume.shape[2:], mode='trilinear', align_corners=False\n",
    "        )\n",
    "\n",
    "        # Fake CT 크기 조정 (직접 정의된 크기로 변경)\n",
    "        fake_ct_resized = torch.nn.functional.interpolate(\n",
    "            self.fake_ct, size=(320, 320, 320), mode='trilinear', align_corners=False\n",
    "        )\n",
    "\n",
    "        # 디버깅 정보를 저장\n",
    "        self.debug_info['xray1_resized_shape'] = xray1_resized.shape\n",
    "        self.debug_info['xray2_resized_shape'] = xray2_resized.shape\n",
    "        self.debug_info['ct_volume_shape'] = self.ct_volume.shape\n",
    "        self.debug_info['fake_ct_resized_shape'] = fake_ct_resized.shape\n",
    "\n",
    "        # Real input 병합\n",
    "        real_input = torch.cat([xray1_resized, xray2_resized, self.ct_volume], dim=1)  # [1, 3, 320, 320, 320]\n",
    "        pred_real = self.netD(real_input)\n",
    "        loss_D_real = self.criterionGAN(pred_real, True)\n",
    "\n",
    "        # Fake input 병합\n",
    "        fake_input = torch.cat([xray1_resized, xray2_resized, fake_ct_resized.detach()], dim=1)  # [1, 3, 320, 320, 320]\n",
    "        fake_input = self.fake_pool.query(fake_input)\n",
    "        pred_fake = self.netD(fake_input)\n",
    "        loss_D_fake = self.criterionGAN(pred_fake, False)\n",
    "\n",
    "        # Loss 계산\n",
    "        self.loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "        self.loss_D.backward()\n",
    "\n",
    "\n",
    "\n",
    "    def backward_G(self):\n",
    "        \"\"\"\n",
    "        Generator 역전파\n",
    "        \"\"\"\n",
    "        print(f\"xray1 type: {type(self.xray1)}, shape: {self.xray1.shape}\")\n",
    "        print(f\"xray2 type: {type(self.xray2)}, shape: {self.xray2.shape}\")\n",
    "        print(f\"fake_ct type: {type(self.fake_ct)}, shape: {self.fake_ct.shape}\")\n",
    "\n",
    "    # X-ray 텐서를 5D로 확장 (depth 차원 추가)\n",
    "        xray1_5d = self.xray1.unsqueeze(2)  # [1, 1, 1, 320, 320]\n",
    "        xray2_5d = self.xray2.unsqueeze(2)  # [1, 1, 1, 320, 320]\n",
    "\n",
    "    # Generator에서 생성된 fake_ct를 5D로 확장\n",
    "        if self.fake_ct.dim() == 5:\n",
    "            fake_ct_5d = self.fake_ct\n",
    "        elif self.fake_ct.dim() == 4:\n",
    "            fake_ct_5d = self.fake_ct.unsqueeze(2)  # [1, 1, 1, 320, 320]\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected fake_ct shape: {self.fake_ct.shape}\")\n",
    "\n",
    "        print(f\"Adjusted fake_ct shape: {fake_ct_5d.shape}\")\n",
    "\n",
    "    # GAN Loss 계산을 위해 fake_ct와 X-ray 병합\n",
    "        fake_input = torch.cat([xray1_5d, xray2_5d, fake_ct_5d], dim=1)  # [1, 3, 1, 320, 320]\n",
    "        pred_fake = self.netD(fake_input)\n",
    "        self.loss_G_GAN = self.criterionGAN(pred_fake, True)\n",
    "\n",
    "    # Reconstruction Loss 계산을 위해 fake_ct_5d 크기를 ct_volume과 일치\n",
    "        fake_ct_resized = torch.nn.functional.interpolate(\n",
    "            self.fake_ct, size=self.ct_volume.shape[2:], mode='trilinear', align_corners=False\n",
    "          )  # [1, 1, 320, 320, 320]\n",
    "\n",
    "        print(f\"Resized fake_ct shape for Reconstruction Loss: {fake_ct_resized.shape}\")\n",
    "\n",
    "    # Reconstruction Loss 계산\n",
    "        self.loss_G_L1 = self.criterionL1(self.ct_volume, fake_ct_resized) * self.opt.idt_lambda\n",
    "\n",
    "    # 총 Generator Loss\n",
    "        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n",
    "        self.loss_G.backward()\n",
    "\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        self.forward()\n",
    "        self.set_requires_grad(self.netD, False)\n",
    "        self.optimizer_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.optimizer_G.step()\n",
    "\n",
    "        self.set_requires_grad(self.netD, True)\n",
    "        self.optimizer_D.zero_grad()\n",
    "        self.backward_D()\n",
    "        self.optimizer_D.step()\n",
    "\n",
    "    def set_requires_grad(self, nets, requires_grad=False):\n",
    "        if not isinstance(nets, list):\n",
    "            nets = [nets]\n",
    "        for net in nets:\n",
    "            if net is not None:\n",
    "                for param in net.parameters():\n",
    "                    param.requires_grad = requires_grad\n",
    "\n",
    "    def get_debug_info(self):\n",
    "        return self.debug_info\n",
    "\n",
    "\n",
    "\n",
    "# Generator와 Discriminator 초기화\n",
    "generator = Generator3D(\n",
    "    input_nc=opt.input_nc_G,\n",
    "    output_nc=opt.output_nc_G,\n",
    "    encoder_input_shape=opt.encoder_input_shape,\n",
    "    encoder_input_channels=opt.encoder_input_nc,\n",
    "    decoder_output_channels=opt.output_nc_G,\n",
    "    decoder_out_activation=nn.Tanh\n",
    ")\n",
    "\n",
    "discriminator = Discriminator3D(\n",
    "    input_nc=opt.input_nc_D,  # 3채널 입력\n",
    "    ndf=opt.ndf,\n",
    "    n_layers=opt.n_layers_D\n",
    ")\n",
    "\n",
    "# CTGAN 초기화\n",
    "ctgan = CTGAN(opt, generator, discriminator)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
