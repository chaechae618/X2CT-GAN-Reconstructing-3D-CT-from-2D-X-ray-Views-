{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097ffa6d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ctgan 객체와 input_data가 준비된 상태라고 가정\n",
    "\n",
    "# 학습 루프\n",
    "num_epochs = 50\n",
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    ctgan.set_input(input_data)  # 데이터 입력\n",
    "    ctgan.optimize_parameters()  # 학습 최적화\n",
    "\n",
    "    # 손실값 저장\n",
    "    generator_loss = ctgan.loss_G.item()\n",
    "    discriminator_loss = ctgan.loss_D.item()\n",
    "    generator_losses.append(generator_loss)\n",
    "    discriminator_losses.append(discriminator_loss)\n",
    "\n",
    "    # 현재 에폭의 손실 출력\n",
    "    print(f\"Generator Loss: {generator_loss:.4f}\")\n",
    "    print(f\"Discriminator Loss: {discriminator_loss:.4f}\")\n",
    "\n",
    "# 손실함수 그래프 출력\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, num_epochs + 1), generator_losses, label=\"Generator Loss\", marker='o')\n",
    "plt.plot(range(1, num_epochs + 1), discriminator_losses, label=\"Discriminator Loss\", marker='x')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Generator and Discriminator Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# 학습 루프 설정\n",
    "num_epochs = 80  # Epoch 추가\n",
    "scheduler_step_epoch = 60  # Learning Rate 감소 시점 변경\n",
    "learning_rate_decay_factor = 0.8  # 학습률 감소 비율\n",
    "gan_loss_weight = 0.5  # GAN Loss 가중치 감소\n",
    "reconstruction_loss_weight = 50.0  # Reconstruction Loss 가중치 증가\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "scheduler_G = StepLR(ctgan.optimizer_G, step_size=scheduler_step_epoch, gamma=learning_rate_decay_factor)\n",
    "scheduler_D = StepLR(ctgan.optimizer_D, step_size=scheduler_step_epoch, gamma=learning_rate_decay_factor)\n",
    "\n",
    "# 손실값 저장\n",
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    ctgan.set_input(input_data)\n",
    "    ctgan.optimize_parameters()\n",
    "\n",
    "    # 손실 계산\n",
    "    generator_loss = (\n",
    "        ctgan.loss_G_GAN.item() * gan_loss_weight +\n",
    "        ctgan.loss_G_L1.item() * reconstruction_loss_weight\n",
    "    )\n",
    "    discriminator_loss = ctgan.loss_D.item()\n",
    "\n",
    "    # 손실값 리스트에 추가\n",
    "    generator_losses.append(generator_loss)\n",
    "    discriminator_losses.append(discriminator_loss)\n",
    "\n",
    "    print(f\"Generator Loss: {generator_loss:.4f}\")\n",
    "    print(f\"Discriminator Loss: {discriminator_loss:.4f}\")\n",
    "\n",
    "    # 학습률 업데이트\n",
    "    if epoch >= scheduler_step_epoch:\n",
    "        scheduler_G.step()\n",
    "        scheduler_D.step()\n",
    "\n",
    "# 손실 함수 그래프 출력\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, num_epochs + 1), generator_losses, label=\"Generator Loss\", marker='o')\n",
    "plt.plot(range(1, num_epochs + 1), discriminator_losses, label=\"Discriminator Loss\", marker='x')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Generator and Discriminator Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
