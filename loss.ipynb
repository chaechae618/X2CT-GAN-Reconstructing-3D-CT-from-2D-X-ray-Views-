{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33b728f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# GAN 손실 함수\n",
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, use_lsgan=True, target_real_label=1.0, target_fake_label=0.0):\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.register_buffer('real_label_tensor', torch.tensor(target_real_label))\n",
    "        self.register_buffer('fake_label_tensor', torch.tensor(target_fake_label))\n",
    "        self.loss = nn.MSELoss() if use_lsgan else nn.BCELoss()\n",
    "        print(f\"GAN loss initialized with {'LSGAN' if use_lsgan else 'Normal GAN'}\")\n",
    "\n",
    "    def get_target_tensor(self, input, target_is_real):\n",
    "        if target_is_real:\n",
    "            target_tensor = self.real_label_tensor\n",
    "        else:\n",
    "            target_tensor = self.fake_label_tensor\n",
    "\n",
    "        if target_tensor.numel() != input.numel():\n",
    "            target_tensor = target_tensor.expand_as(input)\n",
    "        return target_tensor\n",
    "\n",
    "    def forward(self, input, target_is_real):\n",
    "        if isinstance(input[0], list):  # Multi-scale input\n",
    "            loss = 0\n",
    "            for input_i in input:\n",
    "                pred = input_i[-1]\n",
    "                target_tensor = self.get_target_tensor(pred, target_is_real).to(pred.device)\n",
    "                loss += self.loss(pred, target_tensor)\n",
    "            return loss\n",
    "        else:  # Single-scale input\n",
    "            target_tensor = self.get_target_tensor(input[-1], target_is_real).to(input.device)\n",
    "            return self.loss(input[-1], target_tensor)\n",
    "\n",
    "\n",
    "# WGAN 손실 함수\n",
    "class WGANLoss(nn.Module):\n",
    "    def __init__(self, grad_penalty=False, lambda_gp=10):\n",
    "        super(WGANLoss, self).__init__()\n",
    "        self.grad_penalty = grad_penalty\n",
    "        self.lambda_gp = lambda_gp\n",
    "        print(f\"WGAN loss initialized with {'Gradient Penalty' if grad_penalty else 'Weight Clipping'}\")\n",
    "\n",
    "        alpha = torch.rand(real_samples.size(0), 1, 1, 1, device=real_samples.device)\n",
    "        interpolates = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)\n",
    "        d_interpolates = discriminator(interpolates)\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=d_interpolates,\n",
    "            inputs=interpolates,\n",
    "            grad_outputs=torch.ones_like(d_interpolates),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True\n",
    "        )[0]\n",
    "        gradients = gradients.view(gradients.size(0), -1)\n",
    "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "        return self.lambda_gp * gradient_penalty\n",
    "\n",
    "    def forward(self, input_fake, input_real=None, is_G=True, discriminator=None):\n",
    "        if is_G:  # Generator loss\n",
    "            return -torch.mean(input_fake[-1])\n",
    "        else:  # Discriminator loss\n",
    "            disc_loss = torch.mean(input_fake[-1]) - torch.mean(input_real[-1])\n",
    "            if self.grad_penalty:\n",
    "                gradient_penalty = self.compute_gradient_penalty(input_real[-1], input_fake[-1], discriminator)\n",
    "                disc_loss += gradient_penalty\n",
    "            return disc_loss\n",
    "\n",
    "\n",
    "# 재구성 손실 함수\n",
    "class RestructionLoss(nn.Module):\n",
    "    def __init__(self, distance='l1', reduction='mean'):\n",
    "        super(RestructionLoss, self).__init__()\n",
    "        if distance == 'l1':\n",
    "            self.loss = nn.L1Loss(reduction=reduction)\n",
    "        elif distance == 'mse':\n",
    "            self.loss = nn.MSELoss(reduction=reduction)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported distance type: {distance}. Use 'l1' or 'mse'.\")\n",
    "\n",
    "    def forward(self, gt, pred):\n",
    "        if gt.shape != pred.shape:\n",
    "            raise ValueError(f\"Shape mismatch: ground truth shape {gt.shape} and prediction shape {pred.shape}\")\n",
    "        return self.loss(gt, pred)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
